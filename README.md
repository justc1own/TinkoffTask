# TinkoffTask(n-gram model)

Доброго времени суток. Я не очень хорошо умею в гит, не знаю правил оформления документации, поэтому просто расскажу, что сделал.
Итак, я написал генератор речи. В основу лег алгоритм цепей Маркова: для каждого возможного префикса из обучающей выборки я хранил возможные за ним слова и  вероятность, с которой это слово встретится после префикса.

0) В начале программы вас попросят ввести размер *окон*, с которым будет работать программа.
1) Для начала нужно добавить все файлы в список файлов, затем программа обработает информацию этих файлов и начнет работать(функции openFile, textProcessing, delExtra[useless]).
2) Затем исходные тексты будут нарезаны на отрезки заданной длины(функция sliceCorpus)
3) Далее программа построит всевозможные переходы(функции collectTransitions, collectNextWord)
4) Основной момент работы - функция generateChain. Из этой функции запустится функция createChain, которая вернет рандомный отрезок слов, а затем в вечном цикле будет строиться следующее слова на основе статитических данных(функция predictNext)
